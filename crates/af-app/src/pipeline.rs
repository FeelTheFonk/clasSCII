use std::sync::Arc;

use af_core::clock::MediaClock;
use af_core::config::RenderConfig;
use af_core::frame::{AudioFeatures, FrameBuffer};
use arc_swap::ArcSwap;

use crate::cli::Cli;

#[cfg(feature = "video")]
pub type SourceResult = (
    Option<Arc<FrameBuffer>>,
    Option<flume::Receiver<Arc<FrameBuffer>>>,
    Option<flume::Sender<af_source::video::VideoCommand>>,
);

#[cfg(not(feature = "video"))]
pub type SourceResult = (
    Option<Arc<FrameBuffer>>,
    Option<flume::Receiver<Arc<FrameBuffer>>>,
);
/// Start the audio pipeline.
///
/// `audio_arg` can be `"default"` or `"mic"` for microphone capture,
/// or a file path for audio file analysis.
///
/// # Errors
/// Returns an error if the audio device or file is unavailable.
pub fn start_audio(
    audio_arg: &str,
    config: &Arc<ArcSwap<RenderConfig>>,
    clock: Arc<MediaClock>,
) -> anyhow::Result<(
    triple_buffer::Output<AudioFeatures>,
    Option<flume::Sender<af_audio::state::AudioCommand>>,
)> {
    let fps = config.load().target_fps;
    let smoothing = config.load().audio_smoothing;

    match audio_arg {
        "default" | "mic" | "microphone" => {
            log::info!("Starting microphone capture");
            let out = af_audio::state::spawn_audio_thread(fps, smoothing)?;
            Ok((out, None))
        }
        path => {
            let audio_path = std::path::Path::new(path);
            if audio_path.exists() {
                log::info!("Starting audio file analysis: {path}");
                let (cmd_tx, cmd_rx) = flume::bounded(10);
                let out = af_audio::state::spawn_audio_file_thread(
                    audio_path, fps, smoothing, cmd_rx, clock,
                )?;
                Ok((out, Some(cmd_tx)))
            } else {
                anyhow::bail!("Audio source not found: {path}")
            }
        }
    }
}

/// Start the visual source pipeline.
///
/// For static images, returns the image as an Arc-wrapped frame.
/// For dynamic sources (video), returns a receiver channel.
///
/// # Errors
/// Returns an error if source initialization fails.
#[allow(clippy::needless_pass_by_value)] // Arc consumed by spawn_video_thread under #[cfg(feature = "video")]
pub fn start_source(cli: &Cli, clock: Option<Arc<MediaClock>>) -> anyhow::Result<SourceResult> {
    let _ = &clock; // Utilisé uniquement avec feature="video"
    if let Some(ref path) = cli.image {
        let mut source = af_source::image::ImageSource::new(path)?;
        let frame = af_core::traits::Source::next_frame(&mut source);
        #[cfg(feature = "video")]
        return Ok((frame, None, None));
        #[cfg(not(feature = "video"))]
        return Ok((frame, None));
    }

    #[cfg(feature = "video")]
    if let Some(ref path) = cli.video {
        log::info!("Starting video source: {}", path.display());
        let (frame_tx, frame_rx) = flume::bounded(3);
        let (cmd_tx, cmd_rx) = flume::bounded(10);
        af_source::video::spawn_video_thread(path.clone(), frame_tx, cmd_rx, clock)?;
        return Ok((None, Some(frame_rx), Some(cmd_tx)));
    }

    #[cfg(feature = "video")]
    return Ok((None, None, None));
    #[cfg(not(feature = "video"))]
    return Ok((None, None));
}

/// Applique les mappings audio à une copie de la config avant le rendu.
///
/// `onset_envelope` est un signal synthétique calculé dans App (decay exponentiel).
/// `smooth_state` accumule l'EMA per-mapping (redimensionné si nécessaire).
///
/// # Example
/// ```
/// use af_core::config::RenderConfig;
/// use af_core::frame::AudioFeatures;
/// use af_app::pipeline::apply_audio_mappings;
///
/// let mut config = RenderConfig::default();
/// let features = AudioFeatures::default();
/// let mut smooth = vec![];
/// apply_audio_mappings(&mut config, &features, 0.0, &mut smooth);
/// ```
#[allow(clippy::too_many_lines)]
pub fn apply_audio_mappings(
    config: &mut RenderConfig,
    features: &AudioFeatures,
    onset_envelope: f32,
    smooth_state: &mut Vec<f32>,
) {
    use af_core::config::MappingCurve;

    let sensitivity = config.audio_sensitivity;
    let global_smoothing = config.audio_smoothing;

    // Resize smooth_state si le nombre de mappings a changé
    if smooth_state.len() != config.audio_mappings.len() {
        smooth_state.resize(config.audio_mappings.len(), 0.0);
    }

    for (i, mapping) in config.audio_mappings.iter().enumerate() {
        if !mapping.enabled {
            continue;
        }

        let source_value = match mapping.source.as_str() {
            "rms" => features.rms,
            "peak" => features.peak,
            "sub_bass" => features.sub_bass,
            "bass" => features.bass,
            "low_mid" => features.low_mid,
            "mid" => features.mid,
            "high_mid" => features.high_mid,
            "presence" => features.presence,
            "brilliance" => features.brilliance,
            "spectral_centroid" => features.spectral_centroid,
            "spectral_flux" => features.spectral_flux,
            "spectral_flatness" => features.spectral_flatness,
            "beat_intensity" => features.beat_intensity,
            "onset" => {
                if features.onset {
                    1.0
                } else {
                    0.0
                }
            }
            "beat_phase" => features.beat_phase,
            "bpm" => features.bpm / 200.0,
            "timbral_brightness" => features.timbral_brightness,
            "timbral_roughness" => features.timbral_roughness,
            "onset_envelope" => onset_envelope,
            _ => 0.0,
        };

        // Apply response curve
        let shaped = match &mapping.curve {
            MappingCurve::Linear => source_value,
            MappingCurve::Exponential => source_value * source_value,
            MappingCurve::Threshold => {
                if source_value > 0.3 {
                    (source_value - 0.3) / 0.7
                } else {
                    0.0
                }
            }
            MappingCurve::Smooth => source_value * source_value * (3.0 - 2.0 * source_value),
        };

        let raw_delta = shaped * mapping.amount * sensitivity + mapping.offset;

        // Per-mapping EMA smoothing
        let alpha = mapping.smoothing.unwrap_or(global_smoothing);
        smooth_state[i] = smooth_state[i] * (1.0 - alpha) + raw_delta * alpha;
        let delta = smooth_state[i];

        match mapping.target.as_str() {
            "edge_threshold" => {
                config.edge_threshold = (config.edge_threshold + delta).clamp(0.0, 1.0);
            }
            "edge_mix" => {
                config.edge_mix = (config.edge_mix + delta).clamp(0.0, 1.0);
            }
            "contrast" => {
                config.contrast = (config.contrast + delta).clamp(0.1, 3.0);
            }
            "brightness" => {
                config.brightness = (config.brightness + delta).clamp(-1.0, 1.0);
            }
            "saturation" => {
                config.saturation = (config.saturation + delta).clamp(0.0, 3.0);
            }
            "density_scale" => {
                config.density_scale = (config.density_scale + delta).clamp(0.25, 4.0);
            }
            "invert" => {
                if delta > 0.5 {
                    config.invert = !config.invert;
                }
            }
            "beat_flash_intensity" => {
                config.beat_flash_intensity = (config.beat_flash_intensity + delta).clamp(0.0, 2.0);
            }
            "chromatic_offset" => {
                config.chromatic_offset = (config.chromatic_offset + delta).clamp(0.0, 5.0);
            }
            "wave_amplitude" => {
                config.wave_amplitude = (config.wave_amplitude + delta).clamp(0.0, 1.0);
            }
            "color_pulse_speed" => {
                config.color_pulse_speed = (config.color_pulse_speed + delta).clamp(0.0, 5.0);
            }
            "fade_decay" => {
                config.fade_decay = (config.fade_decay + delta).clamp(0.0, 1.0);
            }
            "glow_intensity" => {
                config.glow_intensity = (config.glow_intensity + delta).clamp(0.0, 2.0);
            }
            "zalgo_intensity" => {
                config.zalgo_intensity = (config.zalgo_intensity + delta).clamp(0.0, 1.0);
            }
            _ => {}
        }
    }
}
